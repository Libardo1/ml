{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algebra in Theano\n",
    "\n",
    "#### Table of contents\n",
    "- __[Baby Steps](#baby_steps)__: Adding\n",
    "- __[Advanced](#advanced)__: Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "from theano import function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baby Steps <a id='baby_steps'></a>\n",
    "Notes based on http://deeplearning.net/software/theano/tutorial/adding.html.\n",
    "\n",
    "### Adding two scalars\n",
    "First, something simple: adding two numbers. To do so, we define two variables that we want to add. In theano, all variables are typed. __dscalar__ is the type of a double scalar. Calling __dscalar__ with a string argument creates a named variable for a float scalar (the name is optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = T.dscalar('x')\n",
    "y = T.dscalar('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: __dscalar__ is not a class. $x$ and $y$ are instances of __TensorVariable__. They are assigned the type __dscalar__, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.type is T.dscalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining $x$ and $y$ produces a variable $z$ which represents the addition of $x$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a function that takes $x$ and $y$ as inputs and returns $z$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = function([x, y], z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first argument is a list of variables provided as inputs, while the second argument can be a single variable _or_ a list. The function can be called like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(5.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: There's also __z.eval()__, which can be passed a dictionary mapping $x$ and $y$ to values. It doesn't need to import __function()__, but is otherwise less flexible.\n",
    "### Adding two matrices\n",
    "Now, instead of instantiating $x$ and $y$ as scalars, we create them as matrix types and create another function $f$ to add them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = T.dmatrix('x')\n",
    "y = T.dmatrix('y')\n",
    "z = x + y\n",
    "f = function([x, y], z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use it to sum up matrices, i.e. 2d arrays (1d arrays are vectors). Note: They need to have the same dimensions, naturally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.,   8.],\n",
       "       [ 10.,  12.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f([[1, 2], [3, 4]], [[5, 6], [7, 8]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy arrays can also be used directly as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.,   8.],\n",
       "       [ 10.,  12.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(np.array([[1, 2], [3, 4]]), np.array([[5, 6], [7, 8]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Computation of $a^2 + b^2 + 2 a b$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  28.,  132.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = T.vector()\n",
    "b = T.vector()\n",
    "out = a ** 2 + b ** + 2 * a * b\n",
    "f = function([a, b], out)\n",
    "f([1, 2], [3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced <a id='advanced'></a>\n",
    "Notes based on: http://deeplearning.net/software/theano/tutorial/gradients.html.\n",
    "\n",
    "### Computing Gradients\n",
    "To compute a gradient in Theano, we use __T.grad__. Note that the first argument of __T.grad__ has to be a scalar. Here is the code to compute the gradient of $x^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'((fill((x ** TensorConstant{2}), TensorConstant{1.0}) * TensorConstant{2}) * (x ** (TensorConstant{2} - TensorConstant{1})))'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from theano import pp\n",
    "x = T.dscalar('x')\n",
    "y = x ** 2\n",
    "gy = T.grad(y, x)\n",
    "pp(gy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check with __pp__ if we computed the gradient correctly. Note that __fill((x ** 2), 1.0)__ means to make a matrix of the same shape as $x^2$ and fill it with 1.0.\n",
    "\n",
    "Computing and plotting the gradient of the logistic function, $\\frac{\\partial s}{\\partial x} = s(x) \\cdot (1 - s(x))$, looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f015b640fd0>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEACAYAAAC57G0KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTKCswBtjTKCswBtjTKCswBtjTKD+H6benZXt7SDtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f016c9b0890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "x = T.dscalar()\n",
    "s = 1 / (1 + T.exp(-x))\n",
    "gs = T.grad(s, x)\n",
    "logistic = function([x], gs)\n",
    "plt.grid()\n",
    "values = np.arange(-6, 6, 0.01)\n",
    "plt.plot(values, [logistic(i) for i in values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in order to compute the gradient of the logistic function of a matrix, x has to be specified as a matrix and the sigmoid needs to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = T.sum(1 / (1 + T.exp(-x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the Jacobian\n",
    "The Jacobian matrix is a matrix comprising the first partial derivatives of the output of a function wrt its inputs. The Jacobian is the tensor generalizing this notion. It's computed using __gradient.jacobian__ similarly to the gradient, by first specifying the expression and then wrt what the jacobian should be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  0.,  0.],\n",
       "       [ 0.,  4.,  0.],\n",
       "       [ 0.,  0.,  6.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from theano import gradient\n",
    "x = T.dvector('x')\n",
    "y = x ** 2\n",
    "Jy = gradient.jacobian(y, x)\n",
    "f = function([x], Jy)\n",
    "f([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute the Jacobian manually using __scan__ by looping over the entries in $y$ and computing the gradient of $y_i$ with respect to $x$. We do this by generating a sequence of integers from 0 to __y.shape[0]__ using __T.arange__ and loop through this sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.,  0.],\n",
       "       [ 0.,  8.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from theano import scan\n",
    "x = T.dvector('x')\n",
    "y = x ** 2\n",
    "J, updates = scan(lambda i, y, x: T.grad(y[i], x), sequences=T.arange(y.shape[0]), non_sequences=[y, x])\n",
    "f = function([x], J, updates=updates)\n",
    "f([4, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the Hessian\n",
    "The Hessian is the matrix comprising the second order partial derivatives of a function with scalar output and vector input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  0.,  0.],\n",
       "       [ 0.,  2.,  0.],\n",
       "       [ 0.,  0.,  2.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = T.dvector('x')\n",
    "y = x ** 2\n",
    "cost = y.sum()\n",
    "Hy = gradient.hessian(cost, x)\n",
    "f = function([x], Hy)\n",
    "f([0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, the Hessian can also be computed manually, with the only difference beign that instead of computing the Jacobian of some expression $y$, we compute the gradient of the gradient of a scalar cost wrt $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  0.],\n",
       "       [ 0.,  2.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = T.dvector('x')\n",
    "y = x ** 2\n",
    "cost = y.sum()\n",
    "gy = T.grad(cost, x)\n",
    "H, updates = scan(lambda i, gy, x: T.grad(gy[i], x), sequences=T.arange(gy.shape[0]), non_sequences=[gy, x])\n",
    "f = function([x], H, updates=updates)\n",
    "f([4, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jacobian times a Vector\n",
    "There are special functions to enable faster computation of a Jacobian times a vector.\n",
    "\n",
    "#### R-operator\n",
    "The _R operator_ evaluates the product between a Jacobian and a vector, i.e. $\\frac{\\partial f(x)}{\\partial x} v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  2.])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = T.dmatrix('W')\n",
    "V = T.dmatrix('V')\n",
    "x = T.dvector('x')\n",
    "y = T.dot(x, W)\n",
    "JV = T.Rop(y, W, V)\n",
    "f = function([W, V, x], JV)\n",
    "f([[1, 1], [1, 1]], [[2, 2], [2, 2]], [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L-operator\n",
    "Similarly, the _L-operator_ computes a _row_ vector times a Jacobian, i.e. $v \\frac{\\partial f(x)}{\\partial x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 2.,  2.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = T.dmatrix('W')\n",
    "v = T.dvector('v')\n",
    "x = T.dvector('x')\n",
    "y = T.dot(x, W)\n",
    "VJ = T.Lop(y, W, v)\n",
    "f = function([v, x], VJ)\n",
    "f([2, 2], [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hessian times a vector\n",
    "To compute Hessian times a vector, we can either compute use the _R-operator_ as above or compute the Hessian times a vector without using any special functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.,  4.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = T.dvector('x')\n",
    "v = T.dvector('v')\n",
    "y = T.sum(x ** 2)\n",
    "gy = T.grad(y, x)\n",
    "vH = T.grad(T.sum(gy * v), x)\n",
    "f = function([x, v], vH)\n",
    "f([4, 4], [2, 2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
